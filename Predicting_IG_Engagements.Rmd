---
title: "NBA Hackathon, Business Analytics Question - Tuned Random Forest Model for Predicting Instagram Engagments"
authors: "Daniel Alpert, Nathaniel Hollenberg, Jefferey Huang, Ramtin Talebi"
output: md_document
---
### Introduction

Presented with the task of predicting the number of engagements with Instagram posts of the \textit{@nba} account from the past two years, our team elected to create a partitioned Random Forest Model from the \textit{randomForest} package in \textit{R}. Our models were partitioned based on post medium (The prompt seemed to allude to this as well, so we explored accordingly and confirmed the suggestion). Here we present our process for cleaning and modifying the data, visualizing trends, training the Random Forest, evaluating and tuning it, and finally applying it to predict \textit{Engagements} in our holdout set.

First, we defined functions to calculate predicted values, absolute percent error of each prediction, and mean absolute percent error as follows (this will be useful for training later):

```{r}
## Create useful functions for calculating mape
Calc_Mape <- function(labels, dataset, model)
  {
    actual = labels
    predicted = predict(model, dataset)
    APE = abs((actual - predicted)/actual) * 100
    mape = mean(APE)
    return(mape)
  }
Calc_Predicted <- function(model, dataset)
  {
    predicted = predict(model, dataset)
    return(predicted)
  }
Calc_PE <- function(labels, dataset, model)
  {
    actual = labels
    predicted = predict(model, dataset)
    PE = ((actual - predicted)/actual) * 100
    return (PE)
  }
```

Next we loaded in the necessary packages and read in the training set:

```{r echo=FALSE, results='hide', warning=FALSE,message=FALSE}
## Load necessary libraries and read data
require(caTools)
require(gam)
require(xgboost)
require(Matrix)
library(readr)
library(forcats)
library(stringr)
library(car)
library(dplyr)
library(ggplot2)
library(randomForest)
library(corrplot)
library(Hmisc)

# Read in data
df <- read_csv("data/training_set_final.csv") 
```

## Predictors Preparation and Data Parsing

After sorting and examining the dataset across a number of predictors, we noticed that some of the posts did not contain descriptions and others only contained an emoji or symbol. To avoid any unnecessary influence from these observations, we deleted these entries entirely (while we recognize that imputing the mean for the predictors of these observations is likely a better approach, we felt that this wouldn't entirely be accurate given that they were text descriptions).

In addition, we created variables for the number of instagram accounts mentioned (num\_ats) and the number of hashtags (num\_hash) in each post. We also converted some of our categorical predictors into numerical predictors (useful for creating a Correlation Plot later).

Note: In an attached Python file, you will find some code with our initial modifications to the dataset, including using datetime functions, parsing out important information from the \textit{Created} column and Instagram descriptions.


```{r}
## Deleting missing data

# Order data by post description
df <- df[order(df$Description),]

# Delete descriptions with NAs, just symbols, or just emojis
# and remove season_yr and is_finals column

nba <- df[-c(1:14,20:35),-c(15,17)]
```

By the end, both our training and holdout sets contained the following predictors:

\textbf{X} - Index variable

\textbf{Followers} - # of Followers at time of posting

\textbf{Created} - Timestamp of posting

\textbf{Type} - Type of Post; three factors: \textit{Videos, Albums, Photos}

\textbf{Description} - Post caption

\textbf{datetime} - Datetime variable parsed from \textit{Created}

\textbf{year} - Year it was posted

\textbf{month} - Month posted (parsed \textit{datetime})

\textbf{month\_int} - Numeric variable for months (\textit{1} = January). Useful for correlation plot

\textbf{weekday} - Day of week posted

\textbf{day\_time} - Time of day posted

\textbf{is\_playoffs} - Boolean: whether the post was made in the playoffs (True) or not (False)

\textbf{is\_season} - Boolean: whether the post was made during the season/playoffs (True) or off-season (False)

\textbf{Followers Mentioned} - Number of followers of nba team accounts mentioned in post \textit{Description}

\textbf{all\_nba} - Three factor variable: \textit{0} if no all-nba or all-star players are mentioned in \textit{Description}. \textit{1} if an all-nba is mentioned in the \textit{Description}, not including those to follow. \textit{2} if Lebron James, Stephen Curry, Kyrie Irving, or Kobe Bryant (NBA players with highest number of instagram followers) are mentioned. Although Kobe is retired, posts with his mention appeared to garner more engagements.

\textbf{league\_type} - \textit{1} if \textit{Description} mentioned the WNBA or G-League, \textit{1} otherwise.

\textbf{same\_day\_post} - \textit{1} if post was created within the same \textit{day\_time} on the same day. \textit{0} otherwise. Parsed from \textit{Created}.

\textbf{num\_ats} - Number of hashtags in the \textit{Description}.

\textbf{num\_hash} - Number of @ symbols in the \textit{Description}.

\textbf{Type\_num} - Numerical variable for \textit{Type} (\textit{1} = Video, \textit{2} = Album, \textit{3} = Photo). Useful for correlation plot.

\textbf{wkdy\_num} - Only in training. Numerical variable for \textit{weekday} (\textit{1} = Monday, \textit{7} = Sunday)

\textbf{day\_time\_num} - Only in training. Numerical variable for \textit{day\_time} (\textit{1} = deazone, \textit{7} = postgame)



### Data Visualizations

Here we provide some visualizations of our training data to understand the relationships between some of our predictors and Engagements. First some boxplots of predictors effects on \textit{Engagements}.

```{r echo=FALSE}

nba_graphs <- nba
nba_graphs$all_nba = as.factor(nba$all_nba)
nba_graphs$league_type = as.factor(nba$league_type)
nba_graphs$is_season = as.factor(nba$is_season)
nba_graphs$same_day_post = as.factor(nba$same_day_post)
nba_graphs$num_ats = as.factor(nba$num_ats)
nba_graphs$num_hash = as.factor(nba$num_hash)

g <- ggplot(nba_graphs, aes(x = month, y = Engagements))
g + geom_boxplot(position = "dodge", fill = 'skyblue') + labs(title="Engagements by Month", x= "Month", y="Engagements") + scale_x_discrete(limits = c("October", "November", "December","January", "February","March", "April","May","June","July","August","September")) + theme_minimal()

g <- ggplot(nba_graphs, aes(x = weekday, y = Engagements))
g + geom_boxplot(position = "dodge", fill = "#C3D7A4") + labs(title="Engagements by Day", x= "Weekday", y="Engagements") + scale_x_discrete(limits = c("Monday", "Tuesday", "Wednesday", "Thursday","Friday", "Saturday","Sunday")) + theme_minimal()

g <- ggplot(nba_graphs, aes(x = day_time, y = Engagements))
g + geom_boxplot(position = "dodge", fill = "#52854C") + labs(title="Engagements by Time of Day", x= "day_time", y="Engagements") + scale_x_discrete(limits = c("deadzone", "morning", "lunch", "afternoon","evening", "night","postgame")) + theme_minimal()

g <- ggplot(nba_graphs, aes(x = is_season, y = Engagements))
g + geom_boxplot(position = "dodge", fill = "#FFDB6D") + labs(title="Effect of Being In Season on Engagements", x= "Season or Off-Season", y="Engagements") + theme_minimal()

g <- ggplot(nba_graphs, aes(x = all_nba, y = Engagements))
g + geom_boxplot(position = "dodge", fill = "#C4961A") + labs(title="Effect of Star Players on Engagements", x= "Type of Star Players", y="Engagements") + theme_minimal()

g <- ggplot(nba_graphs, aes(x = league_type, y = Engagements))
g + geom_boxplot(position = "dodge", fill = "#F4EDCA") + labs(title="Effect of NBA vs GLeague vs WNBA on Engagements", x= "Type of League", y="Engagements") + theme_minimal()

g <- ggplot(nba_graphs, aes(x = same_day_post, y = Engagements))
g + geom_boxplot(position = "dodge", fill = "#CC79A7") + labs(title="Effect of Posting in the Same Time Period", x= "Same Time Period", y="Engagements") + theme_minimal()
```

Now let's see how our data looks across post types.

```{r echo= FALSE, warning=FALSE}


# reordering
nba_graphs <- nba_graphs %>% 
  mutate(month = fct_relevel(month, "October", "November", "December","January", "February","March", "April","May","June","July","August","September")) %>% 
  mutate(weekday = fct_relevel(weekday, "Monday", "Tuesday", "Wednesday", "Thursday","Friday", "Saturday","Sunday")) %>% 
  mutate(day_time = fct_relevel(day_time, "deadzone", "morning", "lunch", "afternoon","evening", "night","postgame"))

g <- ggplot(nba_graphs, aes(x = Type, y = Engagements, fill = month))
g + geom_boxplot(position = "dodge", outlier.shape=NA) + labs(title="Engagements by Month (From Start of Season)", x= "Type", y="Engagements", fill="Month") + theme_minimal() 

g <- ggplot(nba_graphs, aes(x = Type, y = Engagements, fill = weekday))
g + geom_boxplot(position = "dodge",outlier.shape=NA) + labs(title="Engagements by Day", x= "Type", y="Engagements", fill="Day of the Week") + theme_minimal()

g <- ggplot(nba_graphs, aes(x = Type, y = Engagements, fill = day_time))
g + geom_boxplot(position = "dodge", outlier.shape=NA) + labs(title="Engagements by Time of Day", x= "Type", y="Engagements", fill="Time Period in the Day") + theme_minimal()

g <- ggplot(nba_graphs, aes(x = Type, y = Engagements, fill = is_season))
g + geom_boxplot(position = "dodge", outlier.shape=NA) + labs(title="Effect of Being In Season on Engagements", x= "Type", y="Engagements", fill="In Season") + theme_minimal()


g <- ggplot(nba_graphs, aes(x = Type, y = Engagements, fill = all_nba))
g + geom_boxplot(position = "dodge", outlier.shape=NA) + labs(title="Effect of Star Players on Engagements", x= "Type", y="Engagements", fill="All NBA Player") + theme_minimal()

g <- ggplot(nba_graphs, aes(x = Type, y = Engagements, fill = league_type))
g + geom_boxplot(position = "dodge", outlier.shape=NA) + labs(title="Effect of NBA vs GLeague vs WNBA on Engagements", x= "Type", y="Engagements", fill="League Type") + theme_minimal()

g <- ggplot(nba_graphs, aes(x = Type, y = Engagements, fill = same_day_post))
g + geom_boxplot(position = "dodge", outlier.shape=NA) + labs(title="Effect of Posting in the Same Time Period", x= "Type", y="Engagements", fill="Same Day Post") + theme_minimal()

```


From our visualizations, one notable result sticks out: The effect of mentioning a superstar player (LBJ, Curry, Kobe, or Kyrie), is quite significant. Other trends seem to be relatively straightforward with some minor exceptions.

\textbf{Multicollinearity}

In order to assess multicollinearity in our predictors, we created a plot to visualize correlations between each variable The first plot displays the pearson correlation coefficient (R) between predictors, shown by the size and color of the circles at each point in the matrix. The second plot shows the same matrix, but this time with insignificant predictors (p-value < 0.01) crossed-out. With the remaining predictors, nothing in particular seems striking, except for two points:

1) The correlation between \textit{Followers\_Mentioned} and \textit{num\_@}. Intuitively this makes sense, a post must mention another team's IG account in order for the \textit{Followers\_Mentioned} to be a non-zero number. It may be worth looking into removing this variable after some cross validation.

2) The correlation between \textit{day\_time\_num} and \textit{same\_day\_post}. Intuitively this makes sense, a post must be, by our definition, during the same time period as another for \textit{same\_day\_post} to return a 1. It may be worth looking into removing one of these variables after some cross validation.


```{r echo = FALSE}

nba_corr <- nba
# Convert all predictors to numerical values
nba_corr$Followers = as.numeric(nba$Followers)
nba_corr$month_int = as.numeric(nba$month_int)
nba_corr$Followers_Mentioned = as.numeric(nba$Followers_Mentioned)
nba_corr$is_season = as.numeric(nba$is_season)
nba_corr$is_playoffs = as.numeric(nba$is_playoffs)
nba_corr$all_nba = as.numeric(nba$all_nba)
nba_corr$league_type = as.numeric(nba$league_type)
nba_corr$same_day_post = as.numeric(nba$same_day_post)
nba_corr$num_ats = as.numeric(nba$num_ats)
nba_corr$num_hash = as.numeric(nba$num_hash)
nba_corr$wkdy_num = as.numeric(nba$wkdy_num)
nba_corr$day_time_num = as.numeric(nba$day_time_num)

# Create a plot correlation matrix
nbavars <- nba_corr[ ,c(3,10,13,15,16:21,23,24)]
res <- cor(nbavars)
res2 <- rcorr(as.matrix(nbavars))

corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)
corrplot(res2$r, type="upper", order="hclust", tl.col = "black", p.mat = res2$P, sig.level = 0.01, insig = "pch",tl.srt = 45)

```

Lastly, as hinted by the prompt, we viewed the distributions of our training data by post type (either Video, Album, or Photo) to determine whether they differed significantly.

While the distribution of Video and Photo distribution seems to be fairly normal, Album appears bimodal, and all three fall under different mean values for Engagements. Based on the plots, it does seem like each distribution is different enough to warrant each having their own model. In addition, the data set contains many more videos than it does photos or albums, so if we chose to simply include post type as a predictor in one model, we'd have to weight each level accordingly. Instead we chose to create three seperate models.

```{r echo=FALSE}
# Density Plot of Engagements Post Type
library(ggplot2)
ggplot(nba) +
  geom_density(aes(x=Engagements, fill=Type), 
                 colour="grey50", alpha=0.5, position="identity") + ylab("Density") + ggtitle("Distribution of Engagements by Post Type")
```



### Model Training and Validation

First we scramble our training set in preparation for building our model.

```{r}
## Subset data for just videos and scramble data
set.seed(92123)
nba <- nba[sample(1:nrow(nba)), ]
```

Although the code is not included here, we tried to create a number of different models, inlcuding a least squares regression model, a gradient boosted model, a model using NLP that vectorized the descriptions column, and even using predicted values from these models into other models. Ultimately, after testing the accuracy of each, we settled on a Random Forest, as it appeared to perform best and was the least overfitted.

In order to train and validate our Random Forest model, we first divide our training set by post type, and then within each division, we subset a small testing data set from our full training set and use it to calculate the MAPE.

More extensive cross-validation methods were used as well, but for brevity's sake, we don't include them here. Our cross-validation was useful in selecting the correct \textit{mtry}, as well as eliminating two predictors that appeared to aid the model little: \textit{same\_day\_post}, and \textit{is\_playoffs}. After eliminating these variables and tuning, our model's improved by over 1%.

```{r}
# Deleting unneeded variables
nbanew <- nba[,c(2,3,4,5,6,9,11,12,15,16,17,18,20,21)] 
nbanew <- nbanew %>% mutate_if(is.character, as.factor)


# Creating Video/Photo/Album subsets from nba data
nba_Video = nbanew[nbanew$Type == "Video",]
nba_Photo = nbanew[nbanew$Type == "Photo",]
nba_Album = nbanew[nbanew$Type == "Album",]

# Splitting Video/Album/Photo subsets into training and test sets
numberOfTrainingSamples_Video <- round(length(nba_Video$Engagements) * .80)
numberOfTrainingSamples_Photo <- round(length(nba_Photo$Engagements) * .80)
numberOfTrainingSamples_Album <- round(length(nba_Album$Engagements) * .80)

train_dataRF_Video <- nba_Video[1:numberOfTrainingSamples_Video,]
test_dataRF_Video <- nba_Video[-(1:numberOfTrainingSamples_Video),]

train_dataRF_Album <- nba_Album[1:numberOfTrainingSamples_Album,]
test_dataRF_Album <- nba_Album[-(1:numberOfTrainingSamples_Album),]

train_dataRF_Photo <- nba_Photo[1:numberOfTrainingSamples_Photo,]
test_dataRF_Photo <- nba_Photo[-(1:numberOfTrainingSamples_Photo),]
```

We then train the Random Forest model to predict \textit{Engagements} on the test set and then calculate and append columns for predicted Engagements, percent error, and absolute percent error.

```{r echo=FALSE}
# Calculating MAPE of training sets

RF_Video <- randomForest(Engagements ~ Followers+month+day_time+weekday+Followers_Mentioned
                         +is_season+all_nba+league_type+num_ats+num_hash,
                         ntree=1000, mtry=7,importance=TRUE, na.rm=TRUE,
                         data=train_dataRF_Video)
RF_Video

RF_Album <- randomForest(Engagements ~ Followers+month+day_time+weekday+Followers_Mentioned
                         +is_season+all_nba+league_type+num_ats+num_hash,
                         ntree=1000, mtry=8,importance=TRUE, na.rm=TRUE,
                         data=train_dataRF_Album)
RF_Album

RF_Photo <- randomForest(Engagements ~ Followers+month+day_time+weekday+Followers_Mentioned
                         +is_season+all_nba+league_type+num_ats+num_hash,
                         ntree=1000, mtry=7,importance=TRUE, na.rm=TRUE,
                         data=train_dataRF_Photo)
RF_Photo

test_dataRF_Video$predicted = Calc_Predicted(RF_Video, test_dataRF_Video)
test_dataRF_Album$predicted = Calc_Predicted(RF_Album, test_dataRF_Album)
test_dataRF_Photo$predicted = Calc_Predicted(RF_Photo, test_dataRF_Photo)

mape_Rf_Video = mean((abs(test_dataRF_Video$Engagements - test_dataRF_Video$predicted)/test_dataRF_Video$Engagements))*100
mape_Rf_Album = mean((abs(test_dataRF_Album$Engagements - test_dataRF_Album$predicted)/test_dataRF_Album$Engagements))*100
mape_Rf_Photo = mean((abs(test_dataRF_Photo$Engagements - test_dataRF_Photo$predicted)/test_dataRF_Photo$Engagements))*100

test_data_net = rbind(test_dataRF_Video, test_dataRF_Album, test_dataRF_Photo)

test_data_net$percent_error = ((test_data_net$Engagements - test_data_net$predicted)/test_data_net$Engagements)*100
test_data_net$APE = abs(test_data_net$percent_error)

mape_Rf = mean((abs(test_data_net$Engagements - test_data_net$predicted)/test_data_net$Engagements))*100
```

```{r}
mape_Rf
```
Our validation MAPE came out to about 5%. Not bad!

Let's take a look at how our percent error is distributed across the testing set.

```{r echo = FALSE}
# Visualization of percent error of our model's predicted values

hist(test_data_net$percent_error, breaks=50, col = 'red', main = "Percent Error Across Training Subset", xlab = "Percent Error")
```
It appears that there are a few extreme outliers in our dataset that the model performs particularly poorly on. One in particular our model overshoots the most appears to be a post about Lebron James at a WNBA game. Intuitively, it makes sense that our model would perform poorly here. Mentioning Lebron would push the model to predict a higher engagement than would be normal for a WNBA game. Given how few outliers are, that the Random Forest is typically robust to outliers, and how rare a post like Lebron at a WNBA game is, we conclude that our model performs quite well.

Here we plot some of our variables to examine which are most critical to our model's accuracy. Notably, it appears that our variables vary in importance between the subsets for Videos, Albums, and Photos. This gives some credibility to our initial assumption that Video, Albums, and Photos should each have their own model.

```{r}
varImpPlot(RF_Video)
varImpPlot(RF_Album)
varImpPlot(RF_Photo)
```

### Final Predictions

Finally, statisfied with our validation results, we train our Random Forest on the whole of the training set and apply it to the 1000-post holdout set.

```{r}
# Read in holdout set and make same modifications as training set


holdout_pre <-
  read.csv("data/holdout_final.csv")

holdout <- holdout_pre[,c(3,4,5,6,7,11,13,14,16,19,20,21,23,24)]
holdout$Engagements <- as.integer(holdout$Engagements)
for (i in 1:length(holdout[,1])){
  if(holdout$is_season[i]==TRUE)(holdout$is_season[i]='True')
  if(holdout$is_season[i]==FALSE)(holdout$is_season[i]='False')
}
holdout$is_season <- as.factor(holdout$is_season)
```

```{r}
## Final models for training and prediction

RF_Video_Final <- randomForest(Engagements ~ Followers+month+day_time
                               +weekday+Followers_Mentioned
                               +is_season+all_nba+league_type+num_ats+num_hash,
                               ntree=1000, mtry=7,importance=TRUE, data=nba_Video)

RF_Photo_Final <- randomForest(Engagements ~ Followers+month+day_time
                               +weekday+Followers_Mentioned
                               +is_season+all_nba+league_type+num_ats+num_hash,
                               ntree=1000, mtry=8,importance=TRUE, data=nba_Photo)

RF_Album_Final <- randomForest(Engagements ~ Followers+month+day_time
                               +weekday+Followers_Mentioned
                               +is_season+all_nba+league_type+num_ats+num_hash,
                               ntree=1000,mtry=7,importance=TRUE, data=nba_Album)
```

```{r}
#Calculate predicted values and append to holdout dataframe
holdout <- holdout %>% mutate_if(is.character, as.factor)

holdout_Video = holdout %>% filter(Type == "Video")
holdout_Photo = holdout %>% filter(Type == "Photo")
holdout_Album = holdout %>% filter(Type == "Album")
holdout_Video$Engagements = round(predict(RF_Video_Final, newdata=holdout_Video))
holdout_Photo$Engagements = round(predict(RF_Photo_Final, newdata=holdout_Photo))
holdout_Album$Engagements = round(predict(RF_Album_Final, newdata=holdout_Album))

holdout <- rbind(holdout_Album, holdout_Photo, holdout_Video)

write_csv(holdout, "holdout_final.csv")
```

The predictions are contained in the attached "holdout.csv" file.

